{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06_2_fancy_softmax_classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNCQw5xy82NXcwpm77Pr1qc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5c4aeiIyI-LN","executionInfo":{"status":"ok","timestamp":1622874851334,"user_tz":-540,"elapsed":22693,"user":{"displayName":"최지수","photoUrl":"","userId":"02873560556130811520"}},"outputId":"1212b715-14db-404d-d196-a10b3d429e25"},"source":["# 드라이브에 접근할 수 있도록 아래 코드 입력\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JTxrhTXfKOGk","executionInfo":{"status":"ok","timestamp":1622874878104,"user_tz":-540,"elapsed":24122,"user":{"displayName":"최지수","photoUrl":"","userId":"02873560556130811520"}},"outputId":"88c81082-9828-4910-c477-02b0380cdd0c"},"source":["import numpy as np\n","import tensorflow as tf\n","\n","filename ='/content/drive/MyDrive/Colab_Notebook/Deep_Learning_For_All/datasets/data-04-zoo.csv'\n","\n","data = np.loadtxt(filename, delimiter=',', dtype=np.float32)\n","\n","x_data = data[:, :-1]\n","\n","nb_clasess = 7 # 0 ~6\n","\n","y_data = data[:, [-1]]\n","y_data = tf.one_hot(y_data, depth=nb_clasess)\n","y_data = tf.reshape(y_data, [-1, nb_clasess])\n","\n","dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data)).batch(len(x_data))\n","\n","W = tf.Variable(tf.random.normal([16, nb_clasess]), name='weight')\n","b = tf.Variable(tf.random.normal([nb_clasess]), name='bias')\n","\n","dataset.element_spec\n","\n","def cost_fn(features, labels):\n","    logits = tf.matmul(features, W) + b\n","    # hypothesis = tf.nn.softmax(logits)\n","    cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n","\n","    cost = tf.reduce_mean(cost_i)\n","\n","    return cost\n","\n","def grad(features, labels):\n","    with tf.GradientTape() as tape:\n","        cost_value = cost_fn(features, labels)\n","        grads = tape.gradient(cost_value, [W, b])\n","    return grads\n","\n","def prediction(features, labels):\n","    pred = tf.argmax(tf.nn.softmax(tf.matmul(features, W) + b), 1)\n","    correct_pred = tf.equal(pred, tf.argmax(labels, 1))\n","    accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float32))\n","\n","    return accuracy\n","\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n","\n","EPOCHS = 2400\n","\n","for step in range(EPOCHS + 1):\n","    for features, labels in iter(dataset):\n","        grads = grad(features, labels)\n","        optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))\n","        if step % 300 == 0:\n","            acc = prediction(features, labels).numpy()\n","            cost = cost_fn(features, labels).numpy()\n","            print(\"iter : {}, cost : {:.4f}, accuracy : {:.4f}\".format(step, cost, acc))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["iter : 0, cost : 6.4891, accuracy : 0.0792\n","iter : 300, cost : 0.4148, accuracy : 0.8812\n","iter : 600, cost : 0.2284, accuracy : 0.9307\n","iter : 900, cost : 0.1517, accuracy : 0.9802\n","iter : 1200, cost : 0.1118, accuracy : 0.9802\n","iter : 1500, cost : 0.0879, accuracy : 0.9901\n","iter : 1800, cost : 0.0721, accuracy : 1.0000\n","iter : 2100, cost : 0.0611, accuracy : 1.0000\n","iter : 2400, cost : 0.0529, accuracy : 1.0000\n"],"name":"stdout"}]}]}